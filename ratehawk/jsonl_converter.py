import json
import csv
import os
from typing import Dict, Any, Set
from collections import defaultdict

class SimpleJSONLToCSV:
    """
    Prosty konwerter JSONL -> CSV bez filtrowania
    WyciÄ…ga WSZYSTKIE dane do pliku CSV
    """
    
    def __init__(self, jsonl_file: str, csv_file: str):
        self.jsonl_file = jsonl_file
        self.csv_file = csv_file
        self.all_keys = set()
        self.total_records = 0
        
    def convert(self, batch_size: int = 5000, progress_interval: int = 100000):
        """
        Konwertuje caÅ‚y plik JSONL do CSV
        
        Args:
            batch_size: Ile rekordÃ³w zapisywaÄ‡ na raz
            progress_interval: Co ile rekordÃ³w pokazaÄ‡ postÄ™p
        """
        
        print(f"ðŸ”„ KonwertujÄ™ {self.jsonl_file} -> {self.csv_file}")
        print(f"ðŸ“Š Parametry: batch_size={batch_size}, progress_interval={progress_interval}")
        
        # Krok 1: Skanowanie struktury
        print("\n1ï¸âƒ£ SkanujÄ™ strukturÄ™ pliku...")
        self._scan_structure()
        
        # Krok 2: Konwersja
        print(f"\n2ï¸âƒ£ KonwertujÄ™ {self.total_records:,} rekordÃ³w...")
        self._convert_data(batch_size, progress_interval)
        
        print(f"\nâœ… Gotowe! CSV zapisany w: {self.csv_file}")
        self._print_summary()
    
    def _scan_structure(self):
        """Pierwszy przejazd - zbiera wszystkie moÅ¼liwe klucze"""
        
        file_size = os.path.getsize(self.jsonl_file)
        processed_bytes = 0
        
        with open(self.jsonl_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                if line.strip():
                    try:
                        record = json.loads(line)
                        self.total_records += 1
                        
                        # Zbierz wszystkie klucze (pÅ‚askie)
                        flat_record = self._flatten_dict(record)
                        self.all_keys.update(flat_record.keys())
                        
                        processed_bytes += len(line.encode('utf-8'))
                        
                        # Progress co 1% pliku
                        if processed_bytes % (file_size // 100 + 1) == 0:
                            progress = (processed_bytes / file_size) * 100
                            print(f"   PostÄ™p skanowania: {progress:.1f}% ({self.total_records:,} rekordÃ³w)")
                            
                    except json.JSONDecodeError:
                        continue
        
        print(f"   âœ… Znaleziono {len(self.all_keys)} unikalnych kolumn")
        print(f"   ðŸ“Š CaÅ‚kowita liczba rekordÃ³w: {self.total_records:,}")
    
    def _convert_data(self, batch_size: int, progress_interval: int):
        """Drugi przejazd - konwertuje dane do CSV"""
        
        # Sortuj kolumny dla konsystentnoÅ›ci
        fieldnames = sorted(list(self.all_keys))
        
        batch = []
        processed = 0
        
        with open(self.jsonl_file, 'r', encoding='utf-8') as infile, \
             open(self.csv_file, 'w', newline='', encoding='utf-8') as outfile:
            
            writer = csv.DictWriter(outfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for line_num, line in enumerate(infile, 1):
                if line.strip():
                    try:
                        record = json.loads(line)
                        
                        # SpÅ‚aszcz rekord
                        flat_record = self._flatten_dict(record)
                        
                        # WypeÅ‚nij brakujÄ…ce kolumny
                        row = {key: flat_record.get(key, '') for key in fieldnames}
                        
                        # Dodaj do batcha
                        batch.append(row)
                        
                        # Zapisz batch
                        if len(batch) >= batch_size:
                            writer.writerows(batch)
                            processed += len(batch)
                            batch = []
                            
                            if processed % progress_interval == 0:
                                progress = (processed / self.total_records) * 100
                                print(f"   ðŸ’¾ Zapisano: {processed:,}/{self.total_records:,} ({progress:.1f}%)")
                        
                    except json.JSONDecodeError:
                        continue
            
            # Zapisz ostatni batch
            if batch:
                writer.writerows(batch)
                processed += len(batch)
        
        print(f"   âœ… Zapisano {processed:,} rekordÃ³w do CSV")
    
    def _flatten_dict(self, data: Dict[str, Any], parent_key: str = '', sep: str = '_') -> Dict[str, str]:
        """
        SpÅ‚aszcza zagnieÅ¼dÅ¼ony sÅ‚ownik do jednego poziomu
        
        Example:
        {'user': {'name': 'John', 'age': 30}} -> {'user_name': 'John', 'user_age': 30}
        """
        items = []
        
        for key, value in data.items():
            new_key = f"{parent_key}{sep}{key}" if parent_key else key
            
            if isinstance(value, dict):
                # Rekurencyjnie spÅ‚aszcz sÅ‚ownik
                items.extend(self._flatten_dict(value, new_key, sep=sep).items())
            elif isinstance(value, list):
                # Konwertuj listÄ™ na string
                if value:
                    # SprawdÅº typ pierwszego elementu
                    if isinstance(value[0], dict):
                        # Lista sÅ‚ownikÃ³w - weÅº pierwszy element i spÅ‚aszcz
                        items.extend(self._flatten_dict(value[0], f"{new_key}_0", sep=sep).items())
                        # Dodaj informacjÄ™ o dÅ‚ugoÅ›ci listy
                        items.append((f"{new_key}_count", len(value)))
                    else:
                        # Lista prostych wartoÅ›ci - poÅ‚Ä…cz pipe'em
                        items.append((new_key, '|'.join(str(v) for v in value)))
                else:
                    # Pusta lista
                    items.append((new_key, ''))
            else:
                # Prosta wartoÅ›Ä‡
                items.append((new_key, str(value) if value is not None else ''))
        
        return dict(items)
    
    def _print_summary(self):
        """WyÅ›wietla podsumowanie konwersji"""
        
        file_size_mb = os.path.getsize(self.csv_file) / (1024 * 1024)
        
        print(f"\nðŸ“‹ PODSUMOWANIE:")
        print(f"   ðŸ“ Plik ÅºrÃ³dÅ‚owy: {self.jsonl_file}")
        print(f"   ðŸ“„ Plik docelowy: {self.csv_file}")
        print(f"   ðŸ“Š RekordÃ³w: {self.total_records:,}")
        print(f"   ðŸ—‚ï¸ Kolumn: {len(self.all_keys)}")
        print(f"   ðŸ’¾ Rozmiar CSV: {file_size_mb:.1f} MB")
        
        # PokaÅ¼ przykÅ‚adowe kolumny
        sample_keys = sorted(list(self.all_keys))[:20]
        print(f"\nðŸ” PrzykÅ‚adowe kolumny (pierwsze 20):")
        for i, key in enumerate(sample_keys, 1):
            print(f"   {i:2d}. {key}")
        
        if len(self.all_keys) > 20:
            print(f"   ... i {len(self.all_keys) - 20} wiÄ™cej")

# Funkcja do szybkiego uÅ¼ycia
def convert_jsonl_to_csv(jsonl_file: str, csv_file: str = None, 
                        batch_size: int = 5000, progress_interval: int = 100000):
    """
    Szybka funkcja do konwersji JSONL -> CSV
    
    Args:
        jsonl_file: ÅšcieÅ¼ka do pliku JSONL
        csv_file: ÅšcieÅ¼ka do pliku CSV (opcjonalna)
        batch_size: Rozmiar batcha
        progress_interval: InterwaÅ‚ raportowania postÄ™pu
    """
    
    if csv_file is None:
        csv_file = jsonl_file.replace('.jsonl', '.csv').replace('.json', '.csv')
    
    converter = SimpleJSONLToCSV(jsonl_file, csv_file)
    converter.convert(batch_size, progress_interval)
    
    return csv_file

# Optimized version for very large files
class OptimizedJSONLToCSV:
    """
    Zoptymalizowana wersja dla bardzo duÅ¼ych plikÃ³w (>10GB)
    """
    
    def __init__(self, jsonl_file: str, csv_file: str):
        self.jsonl_file = jsonl_file
        self.csv_file = csv_file
    
    def convert_streaming(self, sample_size: int = 10000):
        """
        Konwersja streamingowa - prÃ³bkuje strukturÄ™ z pierwszych N rekordÃ³w
        Szybsza dla bardzo duÅ¼ych plikÃ³w
        """
        
        print(f"ðŸš€ OPTYMALIZOWANA KONWERSJA")
        print(f"ðŸ“Š PrÃ³bkujÄ™ strukturÄ™ z pierwszych {sample_size} rekordÃ³w")
        
        # Krok 1: PrÃ³bkuj strukturÄ™
        all_keys = set()
        with open(self.jsonl_file, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f):
                if i >= sample_size:
                    break
                if line.strip():
                    try:
                        record = json.loads(line)
                        flat_record = self._flatten_dict(record)
                        all_keys.update(flat_record.keys())
                    except json.JSONDecodeError:
                        continue
        
        fieldnames = sorted(list(all_keys))
        print(f"   âœ… Znaleziono {len(fieldnames)} kolumn z prÃ³bki")
        
        # Krok 2: Konwertuj caÅ‚y plik
        print(f"\nðŸ”„ KonwertujÄ™ caÅ‚y plik...")
        
        processed = 0
        batch = []
        batch_size = 10000
        
        with open(self.jsonl_file, 'r', encoding='utf-8') as infile, \
             open(self.csv_file, 'w', newline='', encoding='utf-8') as outfile:
            
            writer = csv.DictWriter(outfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for line_num, line in enumerate(infile, 1):
                if line.strip():
                    try:
                        record = json.loads(line)
                        flat_record = self._flatten_dict(record)
                        row = {key: flat_record.get(key, '') for key in fieldnames}
                        batch.append(row)
                        
                        if len(batch) >= batch_size:
                            writer.writerows(batch)
                            processed += len(batch)
                            batch = []
                            
                            if processed % 500000 == 0:
                                print(f"   ðŸ’¾ Przetworzono: {processed:,} rekordÃ³w")
                        
                    except json.JSONDecodeError:
                        continue
            
            # Ostatni batch
            if batch:
                writer.writerows(batch)
                processed += len(batch)
        
        print(f"âœ… Gotowe! Przetworzono {processed:,} rekordÃ³w")
    
    def _flatten_dict(self, data: dict, parent_key: str = '', sep: str = '_') -> dict:
        """Uproszczona wersja flatten dla szybkoÅ›ci"""
        items = []
        for key, value in data.items():
            new_key = f"{parent_key}{sep}{key}" if parent_key else key
            if isinstance(value, dict):
                items.extend(self._flatten_dict(value, new_key, sep=sep).items())
            elif isinstance(value, list):
                items.append((new_key, '|'.join(str(v) for v in value) if value else ''))
            else:
                items.append((new_key, str(value) if value is not None else ''))
        return dict(items)

# PRZYKÅADY UÅ»YCIA
# if __name__ == "__main__":
    
#     print("ðŸ¨ JSONL TO CSV CONVERTER")
#     print("="*50)
    
#     # SPOSÃ“B 1: Podstawowa konwersja
#     print("\n1ï¸âƒ£ PODSTAWOWA KONWERSJA:")
#     convert_jsonl_to_csv('hotels.jsonl', 'hotels_full.csv')
    
#     # SPOSÃ“B 2: Z customowymi parametrami
#     print("\n2ï¸âƒ£ Z CUSTOMOWYMI PARAMETRAMI:")
#     converter = SimpleJSONLToCSV('hotels.jsonl', 'hotels_custom.csv')
#     converter.convert(batch_size=10000, progress_interval=50000)
    
#     # SPOSÃ“B 3: Optimized dla bardzo duÅ¼ych plikÃ³w
#     print("\n3ï¸âƒ£ OPTIMIZED (dla plikÃ³w >10GB):")
#     opt_converter = OptimizedJSONLToCSV('hotels.jsonl', 'hotels_optimized.csv')
#     opt_converter.convert_streaming(sample_size=5000)
    
#     print("\nðŸŽ¯ Wszystkie konwersje zakoÅ„czone!")

# # CLI Usage
# import sys
# if len(sys.argv) >= 2:
#     input_file = sys.argv[1]
#     output_file = sys.argv[2] if len(sys.argv) > 2 else input_file.replace('.jsonl', '.csv')
    
#     print(f"Converting {input_file} -> {output_file}")
#     convert_jsonl_to_csv(input_file, output_file)